
# list of brokers used for bootstrapping knowledge about the rest of the cluster
# format: host1:port1,host2:port2 ...
#metadata.broker.list=data2:9092,data3:9092,data4:9092,data2:9093,data3:9093,data4:9093

# name of the partitioner class for partitioning events; default partition spreads data randomly
#partitioner.class=com.jingoal.msgsend.SimplePartitioner

# specifies whether the messages are sent asynchronously (async) or synchronously (sync)
#producer.type=sync

# specify the compression codec for all data generated: none, gzip, snappy, lz4.
# the old config values work as well: 0, 1, 2, 3 for none, gzip, snappy, lz4, respectively
#compression.codec=gzip

# message encoder
#serializer.class=kafka.serializer.DefaultEncoder
#serializer.class=kafka.serializer.StringEncoder

# allow topic level compression
#compressed.topics=

############################# Async Producer #############################
# maximum time, in milliseconds, for buffering data on the producer queue 
#queue.buffering.max.ms=

# the maximum size of the blocking queue for buffering on the producer 
#queue.buffering.max.messages=

# Timeout for event enqueue:
# 0: events will be enqueued immediately or dropped if the queue is full
# -ve: enqueue will block indefinitely if the queue is full
# +ve: enqueue will block up to this many milliseconds if the queue is full
#queue.enqueue.timeout.ms=

# the number of messages batched at the producer 
#batch.num.messages=
#request.required.acks=1

#queue.enqueueTimeout.ms=-1

acks=1
bootstrap.servers=192.168.10.7:19092,192.168.10.7:19093,192.168.10.8:19092,192.168.10.8:19093,192.168.10.9:19092,192.168.10.9:19093
buffer.memory=67108864 
#batch.size=8196
key.serializer=org.apache.kafka.common.serialization.ByteArraySerializer
value.serializer=org.apache.kafka.common.serialization.ByteArraySerializer
